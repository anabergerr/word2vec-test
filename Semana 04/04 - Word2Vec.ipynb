{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zljehcW10P5q"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/alan-barzilay/NLPortugues/master/imagens/logo_nlportugues.png\"   width=\"150\" align=\"right\">\n",
        "\n",
        "# Lista 4 - Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bUareHn6UqM"
      },
      "source": [
        "______________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw8FPTMX0P5s"
      },
      "source": [
        "Nessa lista nós exploraremos o espaço vetorial gerado pelo algoritmo Word2Vec e algumas de suas propriedades mais interessantes. Veremos como palavras similares se organizam nesse espaço e as relações de palavras com seus sinônimos e antônimos. Também veremos algumas analogias interessantes que o algoritmo é capaz de fazer ao capturar um pouco do nosso uso da língua portuguesa.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vR52KVnq0P5t"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "78a25ca3",
        "outputId": "99346a09-dcee-4883-dc5c-3594e675425c"
      },
      "source": [
        "%pip install gensim"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
            "Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.1\n",
            "    Uninstalling scipy-1.16.1:\n",
            "      Successfully uninstalled scipy-1.16.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "c2434261e54a4efeb8e12c7acffef850"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KUL7X3F0P5u"
      },
      "source": [
        "# Carregando dados\n",
        "\n",
        "\n",
        "Para esta lista nós utilizaremos vetores de palavras, também conhecidos como *embeddings*, para lingua portuguesa fornecidos pelo [NILC](http://www.nilc.icmc.usp.br/nilc/index.php). Nós utilizaremos o embedding de 50 dimensões treinado com o algoritmo Word2Vec (Continous Bag of Words) que pode ser encontrado [aqui](http://www.nilc.icmc.usp.br/embeddings) sob a licensa [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/). Para evitar problemas de mémoria utilizaremos apenas as 200 mil palavras mais comum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sEwqxBvD0Rga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e28df12b-4f74-4b15-d160-97179ef946f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 92.0M  100 92.0M    0     0  8528k      0  0:00:11  0:00:11 --:--:-- 24.0M\n"
          ]
        }
      ],
      "source": [
        "!curl  https://raw.githubusercontent.com/alan-barzilay/NLPortugues/master/Semana%2004/data/word2vec_200k.txt --output 'word2vec_200k.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Bwajr5sQ0P5v"
      },
      "outputs": [],
      "source": [
        "# Carrega word2vec\n",
        "model = KeyedVectors.load_word2vec_format(\"word2vec_200k.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2JYtS1k0P5v"
      },
      "source": [
        "# Similaridade e Distância Cosseno\n",
        "\n",
        "Como comentamos em sala de aula, podemos considerar as palavras como pontos num espaço n-dimensional e podemos examinar a proximidade delas através da similaridade cosseno:\n",
        "$$s = \\frac{u \\cdot v}{||u|| ||v||}, \\textrm{ onde } s \\in [-1, 1] $$\n",
        "\n",
        "\n",
        "## <font color='blue'>Questão 1 </font>\n",
        "Palavras [polissemicas](https://pt.wikipedia.org/wiki/Polissemia) e [homônimas](https://pt.wikipedia.org/wiki/Hom%C3%B3nimo) são palavras que possuem mais de um significado.\n",
        "\n",
        "\n",
        "Utilizando a função `model.most_similar(positive = palavra1)`, que retorna uma lista das palavras mais similares à palavra1, encontre uma palavra que possua múltiplos significados. Observe que na sua lista de 10 palavras mais similares existam palavras relacionadas a mais de um dos seus significados, lembre-se de consultar sua [documentação](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar).\n",
        "\n",
        "Por exemplo, a palavra \"manga\" possui na sua lista de 10 palavras mais similares as palavras \"gola\" e \"lapela\" (que estão relacionadas ao significado de manga de uma camiseta) e a palavra \"maçã\" (que está relacionada ao significado da fruta manga).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qbvAUIa30P5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce5708f-c954-4e8e-a346-0c8ac761a5b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200000 tokens no vocabulário\n"
          ]
        }
      ],
      "source": [
        "# @title Default title text\n",
        "print(len(model.key_to_index), \"tokens no vocabulário\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tem_vocab(kv, w):\n",
        "    return w in kv.key_to_index\n",
        "\n",
        "palavra = \"bateria\"   # troque para a que você quer testar\n",
        "print(tem_vocab(model, palavra))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZDDZzIDiTT8",
        "outputId": "705845d4-f64d-4d21-e340-cc8fbed9edcb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "viz = model.most_similar(positive=[palavra], topn=10)\n",
        "for w, score in viz:\n",
        "    print(f\"{w:20s} {score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT5xXCKgiaS9",
        "outputId": "018ba56e-cfd0-4045-b4c4-9013a03681f6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guitarra             0.8475\n",
            "pêndula              0.8291\n",
            "lambreta             0.8275\n",
            "lata-velha           0.8274\n",
            "corneta              0.8167\n",
            "batedeira            0.8112\n",
            "fieira               0.8106\n",
            "buzina               0.8067\n",
            "histуria             0.8062\n",
            "afinação             0.8043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Âncoras de exemplo (ajuste para seu domínio/corpora)\n",
        "SENSE_ANCHORS = {\n",
        "    \"manga\": {\n",
        "        \"roupa\": {\"gola\",\"lapela\",\"camisa\",\"casaco\",\"tecido\",\"costura\",\"blusa\",\"punho\"},\n",
        "        \"fruta\": {\"fruta\",\"maçã\",\"banana\",\"goiaba\",\"mamão\",\"abacaxi\",\"suco\",\"pé\",\"colheita\"}\n",
        "    },\n",
        "    \"banco\": {\n",
        "        \"financeiro\": {\"agência\",\"conta\",\"cheque\",\"financiamento\",\"crédito\",\"poupança\",\"juros\",\"caixa\",\"empréstimo\"},\n",
        "        \"assento\": {\"cadeira\",\"banco_de_madeira\",\"assento\",\"praça\",\"jardim\",\"banquinho\",\"sentar\"},\n",
        "        \"geografia\": {\"areia\",\"rio\",\"banco_de_areia\",\"margem\"}\n",
        "    },\n",
        "    \"sede\": {\n",
        "        \"sede_sede\": {\"sede\",\"sede_de\",\"bebida\",\"água\",\"sedento\"},\n",
        "        \"quartel_general\": {\"matriz\",\"hq\",\"escritório\",\"filial\",\"subsidiária\",\"administração\"}\n",
        "    },\n",
        "    # adicione outras palavras candidatas…\n",
        "}\n",
        "\n",
        "def checa_polissemia(kv, palavra, topn=10):\n",
        "    if palavra not in kv.key_to_index:\n",
        "        return {\"ok\": False, \"motivo\": \"fora do vocabulário\"}\n",
        "    viz = [w for w,_ in kv.most_similar(positive=[palavra], topn=topn)]\n",
        "    sentidos = SENSE_ANCHORS.get(palavra, {})\n",
        "    hits_por_sentido = defaultdict(list)\n",
        "    for sentido, anchors in sentidos.items():\n",
        "        for w in viz:\n",
        "            if w in anchors:\n",
        "                hits_por_sentido[sentido].append(w)\n",
        "    return {\n",
        "        \"palavra\": palavra,\n",
        "        \"vizinhos\": viz,\n",
        "        \"hits_por_sentido\": dict(hits_por_sentido),\n",
        "        \"sentidos_com_hits\": [s for s,hs in hits_por_sentido.items() if hs],\n",
        "        \"ok\": sum(1 for hs in hits_por_sentido.values() if hs) >= 2\n",
        "    }\n",
        "\n",
        "print(checa_polissemia(model, \"manga\"))\n",
        "print(checa_polissemia(model, \"banco\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t91jw7REjeFg",
        "outputId": "08a07966-d4c5-45c5-a8aa-145c52ad0d89"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'palavra': 'manga', 'vizinhos': ['lapela', 'gola', 'cola', 'maça', 'serapilheira', 'aréola', 'cachaça', 'pantera', 'cuia', 'canela'], 'hits_por_sentido': {'roupa': ['lapela', 'gola']}, 'sentidos_com_hits': ['roupa'], 'ok': False}\n",
            "{'palavra': 'banco', 'vizinhos': ['observatório', 'governo', 'consórcio', 'comitж', 'orуamento', 'tesouro', 'mercado', 'setor', 'monopólio', 'cine-theatro'], 'hits_por_sentido': {}, 'sentidos_com_hits': [], 'ok': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def cluster_vizinhos(model, palavra, topn=20, k=2):\n",
        "    viz = model.most_similar(positive=[palavra], topn=topn)\n",
        "    words = [w for w,_ in viz]\n",
        "    X = np.vstack([model[w] for w in words])\n",
        "    km = KMeans(n_clusters=k, n_init=10, random_state=42).fit(X)\n",
        "    clusters = {}\n",
        "    for w, c in zip(words, km.labels_):\n",
        "        clusters.setdefault(c, []).append(w)\n",
        "    return clusters\n",
        "\n",
        "clusters = cluster_vizinhos(model, \"manga\", topn=20, k=2)\n",
        "for cid, itens in clusters.items():\n",
        "    print(f\"\\nCluster {cid}:\")\n",
        "    print(\", \".join(itens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enCB2w91jrkU",
        "outputId": "e5cf41b3-033c-402e-8054-995a540ebe7c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cluster 0:\n",
            "lapela, gola, maça, aréola, cuia, sotaina, lousa, argola, alcatifa\n",
            "\n",
            "Cluster 1:\n",
            "cola, serapilheira, cachaça, pantera, canela, madeira, laranja, tequila, seda, areia, palha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLh82IfO0P5x"
      },
      "source": [
        "\n",
        "**<font color='red'> Sua resposta aqui </font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6YKYZ_z0P5x"
      },
      "source": [
        "# Sinônimos e Antônimos\n",
        "\n",
        "\n",
        "As vezes é mais intuitivo trabalhar com uma medida de distancia ao invés da similaridade cosseno, para isso vamos utilizar a distancia cosseno que é simplesmente 1 - Similaridade Cosseno.\n",
        "\n",
        "## <font color='blue'>Questão 2 </font>\n",
        "\n",
        "\n",
        "Usando a função [`model.distance(palavra1,palavra2)`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.distance), encontre 3 palavras onde as palavras p1 e p2 são sinônimas e p1 e p3 são antônimas mas `distance(p1,p3)` < `distance(p1,p2)`.\n",
        "\n",
        "Proponha uma explicação do porque esse resultado contraintuitivo acontece.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JeywFdKk0P5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc3204c-49e8-4339-d689-5a136add9f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distância(forte, robusto) = 0.3109\n",
            "Distância(forte, fraco) = 0.2092\n",
            "➡ Contraintuitivo: 'forte' está mais próximo de 'fraco' (antônimo) do que de 'robusto' (sinônimo).\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Carregue seu modelo já treinado (ajuste o caminho conforme seu arquivo)\n",
        "# Exemplo se for word2vec binário:\n",
        "# kv = KeyedVectors.load_word2vec_format(\"caminho/word2vec.bin\", binary=True)\n",
        "\n",
        "# Para este exemplo, vamos supor que já temos o modelo carregado em `kv`\n",
        "\n",
        "p1 = \"forte\"\n",
        "p2 = \"robusto\"     # sinônimo\n",
        "p3 = \"fraco\"       # antônimo\n",
        "\n",
        "# Conferir se estão no vocabulário\n",
        "for w in [p1, p2, p3]:\n",
        "    if w not in model.key_to_index:\n",
        "        print(f\"{w} não está no vocabulário\")\n",
        "\n",
        "# Calcular distâncias\n",
        "d12 = model.distance(p1, p2)  # bom x excelente\n",
        "d13 = model.distance(p1, p3)  # bom x ruim\n",
        "\n",
        "print(f\"Distância({p1}, {p2}) = {d12:.4f}\")\n",
        "print(f\"Distância({p1}, {p3}) = {d13:.4f}\")\n",
        "\n",
        "if d13 < d12:\n",
        "    print(f\"➡ Contraintuitivo: '{p1}' está mais próximo de '{p3}' (antônimo) do que de '{p2}' (sinônimo).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ncOIj240P5y"
      },
      "source": [
        "\n",
        "**<font color='red'> O modelo aproxima palavras que ocorrem em contextos semelhantes, não palavras que têm o mesmo significado.\n",
        "Por isso, às vezes, antônimos ficam mais próximos do que sinônimos, porque aparecem nas mesmas construções de frase, enquanto sinônimos podem variar mais no uso. </font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9Se982Q0P5z"
      },
      "source": [
        "# Analogias\n",
        "\n",
        "Existem algumas analogias famosas realizadas por vetores de palavras. O exemplo mais famoso é provavelmente \"man : king :: woman : x\", onde x é *queen*.\n",
        "\n",
        "Para formular analogias vamos utilizar a função `most_similar()` que busca as palavras mais similares as listas em  `positive` e mais dissimilares as listadas em  `negative`. Para mais detalhes recomendamos consultar a sua [documentação](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "A8zujhY70P5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144e5467-4834-41bb-ffca-908d6cb9e15e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('vento', 0.8535684943199158), ('sedimento', 0.8110452890396118), ('resfriamento', 0.7972230315208435), ('nevoeiro', 0.7859594821929932), ('estômago', 0.7845367193222046), ('ruído', 0.7833989858627319), ('fluído', 0.7799857258796692), ('cozimento', 0.7734391689300537), ('fotoperíodo', 0.7702401876449585), ('fumo', 0.7679013609886169)]\n"
          ]
        }
      ],
      "source": [
        "result = model.most_similar(positive=[\"inverno\", \"calor\"], negative=[\"verão\"] )\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJnuDjo-0P5z"
      },
      "source": [
        "## <font color='blue'>Questão 3 </font>\n",
        "Encontre analogias que funcionam, ou seja, que a palavra esperada está no topo da lista.\n",
        "\n",
        "Descreva sua analogia na seguinte forma:\n",
        "x:y :: a:b\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "BXpu7g3a0P50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb96396-47e4-4a5b-b4d8-0cd696d6b150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('vento', 0.8535684943199158), ('sedimento', 0.8110452890396118), ('resfriamento', 0.7972230315208435), ('nevoeiro', 0.7859594821929932), ('estômago', 0.7845367193222046), ('ruído', 0.7833989858627319), ('fluído', 0.7799857258796692), ('cozimento', 0.7734391689300537), ('fotoperíodo', 0.7702401876449585), ('fumo', 0.7679013609886169)]\n"
          ]
        }
      ],
      "source": [
        "result = model.most_similar(positive=[\"inverno\", \"calor\"], negative=[\"verão\"] )\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "788u4d3A0P50"
      },
      "source": [
        "\n",
        "**<font color='red'> Sua resposta aqui </font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su8svdBl0P50"
      },
      "source": [
        "## <font color='blue'>Questão 4 </font>\n",
        "Encontre analogias que **Não** funcionam.\n",
        "\n",
        "Descreva o resultado esperado da sua analogia na seguinte forma:\n",
        "x:y :: a:b\n",
        "\n",
        "E indique o valor errado de b encontrado\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "PdQ2rtyA0P51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8742f59e-7ea4-4082-b618-5eea7dbb9916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rei:rainha :: homem: crianção -> similaridade: 0.6878494620323181\n",
            "rápido:devagar :: alto: sossegado -> similaridade: 0.7118181586265564\n",
            "cachorro:filhote :: gato: frêmito -> similaridade: 0.8587124347686768\n",
            "música:violão :: desenho: teclado -> similaridade: 0.8038460612297058\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1ª analogia: rei : rainha :: homem : ?\n",
        "result1 = model.most_similar(positive=['rainha','homem'], negative=['rei'], topn=1)\n",
        "print(\"rei:rainha :: homem:\", result1[0][0], \"-> similaridade:\", result1[0][1])\n",
        "\n",
        "# 2ª analogia: rápido : devagar :: alto : ?\n",
        "result2 = model.most_similar(positive=['devagar','alto'], negative=['rápido'], topn=1)\n",
        "print(\"rápido:devagar :: alto:\", result2[0][0], \"-> similaridade:\", result2[0][1])\n",
        "\n",
        "# 3ª analogia: cachorro : filhote :: gato : ?\n",
        "result3 = model.most_similar(positive=['filhote','gato'], negative=['cachorro'], topn=1)\n",
        "print(\"cachorro:filhote :: gato:\", result3[0][0], \"-> similaridade:\", result3[0][1])\n",
        "\n",
        "\n",
        "# 5ª analogia: música : violão :: desenho : ?\n",
        "result5 = model.most_similar(positive=['violão','desenho'], negative=['música'], topn=1)\n",
        "print(\"música:violão :: desenho:\", result5[0][0], \"-> similaridade:\", result5[0][1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CMzT3fy0P51"
      },
      "source": [
        "Mesmo que a similaridade seja alta, o modelo não garante que a resposta seja correta.\n",
        "\n",
        "Analogias não funcionam quando o modelo não aprendeu bem a relação ou quando a relação é abstrata/menos comum.\n",
        "\n",
        "Por isso, essas analogias são exemplos perfeitos de “analogias que não funcionam”, como a questão pede."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8LYWJ1i0P51"
      },
      "source": [
        "# Viés e preconceito adquirido\n",
        "\n",
        "Como estes vetores são aprendidos a partir de documentos produzidos pela nossa sociedade, ele pode vir a capturar alguns preconceitos e desigualdades presentes na nossa sociedade. É importante estar ciente desse viés de nossos vetores e dos seus perigos, aplicações que utilizam esses modelos podem acabar perpetuando e até mesmo exacerbando desigualdades sociais.\n",
        "\n",
        "Por exemplo, uma analogia problemática capturada:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "53KYiqsc0P51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258f7093-715f-4bb1-c0a6-a4bf5a61fb92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('branco', 0.663209080696106),\n",
              " ('alegre/rs', 0.6620162725448608),\n",
              " ('braga-fc', 0.6464027762413025),\n",
              " ('sporting-fc', 0.6254758238792419),\n",
              " ('côvo', 0.6254613995552063),\n",
              " ('alegre-rs', 0.6199708580970764),\n",
              " ('vermelho', 0.612277090549469),\n",
              " ('covo', 0.604120671749115),\n",
              " ('cirílicos', 0.6022458672523499),\n",
              " ('benfica-fc', 0.5965930819511414)]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "model.most_similar(positive=['negro', 'rico'], negative=['pobre'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS-sruEp0P52"
      },
      "source": [
        "Note também como diferem as palavras mais semelhantes a homem e mulher:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "bgtl4cgN0P53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53341f81-1920-4e24-b178-2dad65f5708f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('monstro', 0.9085395932197571),\n",
              " ('bebé', 0.9072304368019104),\n",
              " ('indivíduo', 0.9050756096839905),\n",
              " ('rapaz', 0.9036115407943726),\n",
              " ('mendigo', 0.9007540345191956),\n",
              " ('rapazola', 0.8992964029312134),\n",
              " ('novelo', 0.8938027620315552),\n",
              " ('pássaro', 0.8897998929023743),\n",
              " ('cão', 0.8882535099983215),\n",
              " ('cãozinho', 0.8869855403900146)]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "model.most_similar(\"homem\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "bExfFYGS0P53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fda7ab6-c9da-41f7-db92-721393017c45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('menina', 0.911119282245636),\n",
              " ('amiga', 0.9089193344116211),\n",
              " ('cadela', 0.9035040140151978),\n",
              " ('rapariga', 0.899989902973175),\n",
              " ('enfermeira', 0.8974366784095764),\n",
              " ('namorada', 0.8954240083694458),\n",
              " ('cafetina', 0.8932163119316101),\n",
              " ('prostituta', 0.8917951583862305),\n",
              " ('garota', 0.8906298279762268),\n",
              " ('cadelinha', 0.8902611136436462)]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "model.most_similar(\"mulher\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgNf_9-P0P53"
      },
      "source": [
        "## <font color='blue'>Questão 5 </font>\n",
        "\n",
        "Utiliza a função `most_similar()` para encontrar um outro caso de viés adquirido pelos vetores e explique brevemente o tipo de viés encontrado.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "FuHqTKSB0P53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c76ad868-a1a6-4f5c-b7b9-133a751d16d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('arquitetura', 0.7338955402374268)]\n"
          ]
        }
      ],
      "source": [
        "result = model.most_similar(positive=[\"jovem\", \"tecnologia\"], negative=[\"idoso\"], topn=1)\n",
        "print(result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ViJvM-RwxGDA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TID_Rbk70P53"
      },
      "source": [
        "\n",
        "**<font color='red'> Sua resposta aqui </font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uqpivEBPw2-K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5ih_CvL0P53"
      },
      "source": [
        "## <font color='blue'>Questão 6 </font>\n",
        "\n",
        "Qual é a possivel origem desses vieses? Tente explicar como eles podem ter sido capturados pelos vetores de palavras."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado foi \"arquitetura\", o que sugere que o modelo associa jovens com tecnologia e idosos não. O tipo de viés que aparece aqui é relacionado a idade e atividade/inteligência tecnológica, ou seja, o modelo reflete um estereótipo cultural: jovens usam ou dominam tecnologia mais que pessoas idosas.\n",
        "\n",
        "Dados de treino: Modelos de word embeddings como Word2Vec são treinados em grandes corpora de texto da internet. Se o corpus tem textos que falam mais sobre \"jovem\" e \"tecnologia\" juntos (ex.: posts em redes sociais, artigos de startups), o vetor de \"jovem\" vai ficar mais próximo de \"tecnologia\".\n",
        "\n",
        "Menor presença de \"idoso\" em contextos tecnológicos: Se textos associando idosos à tecnologia são raros ou negativos, o embedding de \"idoso\" fica distante de palavras relacionadas a tecnologia.\n",
        "\n",
        "Co-ocorrência e contexto: Embeddings capturam co-ocorrência de palavras. Quanto mais duas palavras aparecem juntas em contextos semelhantes, mais próximos elas ficam no espaço vetorial. Por isso, estereótipos do mundo real se refletem nos vetores."
      ],
      "metadata": {
        "id": "ELH9il3exHYT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xExgdiX-w3Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm8ty0WH0P54"
      },
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of Lista 04 - Word2Vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".main_env",
      "language": "python",
      "name": ".main_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}